#!/usr/bin/env python3
"""
import-csv-data.py - å¾ Google Sheets CSV export åŒ¯å…¥åˆ° PostgreSQL
ä½¿ç”¨ Python requests è·³éèªè­‰å•é¡Œ
"""

import requests
import csv
import json
import psycopg2
from psycopg2.extras import execute_values
import os
from io import StringIO
import sys

# PostgreSQL é€£ç·šè¨­å®š
DB_CONFIG = {
    'host': 'tpe1.clusters.zeabur.com',
    'port': 27883,
    'user': 'root',
    'password': 'etUh2zkR4Mr8gfWLs059S7Dm1T6Yby3Q',
    'database': 'zeabur'
}

# è¦†è“‹ç‚ºç’°å¢ƒè®Šæ•¸ï¼ˆå¦‚æœæœ‰ï¼‰
if os.getenv('DATABASE_URL'):
    # PostgreSQL URI æ ¼å¼: postgresql://user:password@host:port/database
    from urllib.parse import urlparse
    db_url = urlparse(os.getenv('DATABASE_URL'))
    DB_CONFIG = {
        'host': db_url.hostname,
        'port': db_url.port,
        'user': db_url.username,
        'password': db_url.password,
        'database': db_url.path.lstrip('/')
    }

# Google Sheets CSV export URLs
SHEETS = {
    'candidates': {
        'sheet_id': '1PunpaDAFBPBL_I76AiRYGXKaXDZvMl1c262SEtxRk6Q',
        'gid': '142613837',
        'name': 'å±¥æ­·æ± ç´¢å¼•'
    },
    'jobs': {
        'sheet_id': '1QPaeOm-slNVFCeM8Q3gg3DawKjzp2tYwyfquvdHlZFE',
        'gid': '0',
        'name': 'è·ç¼ºç®¡ç†'
    }
}

def get_csv_url(sheet_id, gid):
    """ç”Ÿæˆ Google Sheets CSV export URL"""
    return f'https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&gid={gid}'

def fetch_csv(sheet_id, gid, name):
    """ä¸‹è¼‰ CSV è³‡æ–™"""
    url = get_csv_url(sheet_id, gid)
    print(f'\nğŸ“¥ ä¸‹è¼‰ {name}...')
    
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # æª¢æŸ¥æ˜¯å¦æˆåŠŸ
        if '<HTML>' in response.text or '<html>' in response.text:
            print(f'âŒ ä¸‹è¼‰å¤±æ•—ï¼šè¿”å› HTML é é¢ï¼ˆå¯èƒ½æ˜¯èªè­‰å•é¡Œï¼‰')
            return None
        
        lines = response.text.strip().split('\n')
        print(f'âœ… ä¸‹è¼‰æˆåŠŸï¼š{len(lines)} è¡Œï¼ˆå«æ¨™é¡Œï¼‰')
        return response.text
    except Exception as e:
        print(f'âŒ ä¸‹è¼‰éŒ¯èª¤ï¼š{e}')
        return None

def parse_csv(csv_text):
    """è§£æ CSV ä¸¦è¿”å›è¡Œæ¸…å–®"""
    f = StringIO(csv_text)
    reader = csv.DictReader(f)
    rows = list(reader)
    return rows

def import_candidates(conn, rows):
    """åŒ¯å…¥å€™é¸äººè³‡æ–™"""
    if not rows:
        print('âŒ æ²’æœ‰å€™é¸äººè³‡æ–™')
        return 0
    
    print(f'\nğŸ“Š åŒ¯å…¥ {len(rows)} ä½å€™é¸äºº...')
    
    cursor = conn.cursor()
    
    # æ¸…ç©ºç¾æœ‰è³‡æ–™ï¼ˆå¦‚æœé‡æ–°åŒ¯å…¥ï¼‰
    # cursor.execute('TRUNCATE TABLE candidates_pipeline CASCADE')
    
    inserted = 0
    for i, row in enumerate(rows):
        try:
            # æ§‹å»º SQL INSERT
            sql = """
            INSERT INTO candidates_pipeline (
                id, name, email, phone, location, current_position,
                years_experience, job_changes, avg_tenure_months, 
                recent_gap_months, skills, education, source,
                work_history, leaving_reason, stability_score,
                education_details, personality, status, recruiter,
                notes, resume_url, created_at, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
            ON CONFLICT (id) DO UPDATE SET
                name = EXCLUDED.name,
                email = EXCLUDED.email,
                status = EXCLUDED.status,
                updated_at = NOW();
            """
            
            # è§£ææŠ€èƒ½ï¼ˆé€—è™Ÿåˆ†éš” â†’ JSON é™£åˆ—ï¼‰
            skills = row.get('æŠ€èƒ½', '').split(',') if row.get('æŠ€èƒ½') else []
            skills = [s.strip() for s in skills if s.strip()]
            
            # ç”Ÿæˆå”¯ä¸€ IDï¼ˆä½¿ç”¨ name + email hashï¼‰
            candidate_id = f"{row.get('å§“å', 'unknown')}_{i}".replace(' ', '_')
            
            cursor.execute(sql, (
                candidate_id,
                row.get('å§“å', ''),
                row.get('Email', ''),
                row.get('é›»è©±', ''),
                row.get('åœ°é»', ''),
                row.get('ç›®å‰è·ä½', ''),
                int(row.get('ç¸½å¹´è³‡(å¹´)', 0)) if row.get('ç¸½å¹´è³‡(å¹´)') else 0,
                int(row.get('è½‰è·æ¬¡æ•¸', 0)) if row.get('è½‰è·æ¬¡æ•¸') else 0,
                int(row.get('å¹³å‡ä»»è·(æœˆ)', 0)) if row.get('å¹³å‡ä»»è·(æœˆ)') else 0,
                int(row.get('æœ€è¿‘gap(æœˆ)', 0)) if row.get('æœ€è¿‘gap(æœˆ)') else 0,
                json.dumps(skills),
                row.get('å­¸æ­·', ''),
                row.get('ä¾†æº', ''),
                row.get('å·¥ä½œç¶“æ­·JSON', '') or '{}',
                row.get('é›¢è·åŸå› ', ''),
                int(row.get('ç©©å®šæ€§è©•åˆ†', 0)) if row.get('ç©©å®šæ€§è©•åˆ†') else 0,
                row.get('å­¸æ­·JSON', '') or '{}',
                row.get('DISC/Big Five', '') or '{}',
                row.get('ç‹€æ…‹', 'æ–°é€²'),
                row.get('çµé ­é¡§å•', 'Jacky'),
                row.get('å‚™è¨»', ''),
                row.get('å±¥æ­·é€£çµ', '')
            ))
            inserted += 1
            
            if (i + 1) % 50 == 0:
                print(f'  âœ“ å·²åŒ¯å…¥ {i + 1} ç­†...')
        
        except Exception as e:
            print(f'  âš ï¸  ç¬¬ {i + 1} ç­†éŒ¯èª¤ï¼š{e}')
            continue
    
    conn.commit()
    print(f'âœ… æˆåŠŸåŒ¯å…¥ {inserted} ä½å€™é¸äºº')
    cursor.close()
    return inserted

def import_jobs(conn, rows):
    """åŒ¯å…¥è·ç¼ºè³‡æ–™"""
    if not rows:
        print('âŒ æ²’æœ‰è·ç¼ºè³‡æ–™')
        return 0
    
    print(f'\nğŸ“Š åŒ¯å…¥ {len(rows)} å€‹è·ç¼º...')
    
    cursor = conn.cursor()
    
    # æ¸…ç©ºç¾æœ‰è³‡æ–™ï¼ˆå¦‚æœé‡æ–°åŒ¯å…¥ï¼‰
    # cursor.execute('TRUNCATE TABLE jobs_pipeline CASCADE')
    
    inserted = 0
    for i, row in enumerate(rows):
        try:
            # è§£ææŠ€èƒ½ï¼ˆé€—è™Ÿåˆ†éš” â†’ JSON é™£åˆ—ï¼‰
            key_skills = row.get('ä¸»è¦æŠ€èƒ½', '').split(',') if row.get('ä¸»è¦æŠ€èƒ½') else []
            key_skills = [s.strip() for s in key_skills if s.strip()]
            
            # ç”Ÿæˆå”¯ä¸€ ID
            job_id = f"{row.get('è·ä½åç¨±', 'unknown')}_{i}".replace(' ', '_')
            
            sql = """
            INSERT INTO jobs_pipeline (
                id, position_name, client_company, department,
                open_positions, salary_range, key_skills,
                experience_required, education_required, location,
                job_status, language_required, special_conditions,
                industry_background, team_size, key_challenges,
                attractive_points, recruitment_difficulty,
                interview_process, consultant_notes,
                created_at, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
            ON CONFLICT (id) DO UPDATE SET
                position_name = EXCLUDED.position_name,
                updated_at = NOW();
            """
            
            cursor.execute(sql, (
                job_id,
                row.get('è·ä½åç¨±', ''),
                row.get('å®¢æˆ¶å…¬å¸', ''),
                row.get('éƒ¨é–€', ''),
                int(row.get('éœ€æ±‚äººæ•¸', 1)) if row.get('éœ€æ±‚äººæ•¸') else 1,
                row.get('è–ªè³‡ç¯„åœ', ''),
                json.dumps(key_skills),
                row.get('ç¶“é©—è¦æ±‚', ''),
                row.get('å­¸æ­·è¦æ±‚', ''),
                row.get('å·¥ä½œåœ°é»', ''),
                row.get('è·ä½ç‹€æ…‹', 'æ‹›å‹Ÿä¸­'),
                row.get('èªè¨€è¦æ±‚', ''),
                row.get('ç‰¹æ®Šæ¢ä»¶', ''),
                row.get('ç”¢æ¥­èƒŒæ™¯è¦æ±‚', ''),
                row.get('åœ˜éšŠè¦æ¨¡', ''),
                row.get('é—œéµæŒ‘æˆ°', ''),
                row.get('å¸å¼•äº®é»', ''),
                row.get('æ‹›å‹Ÿå›°é›£é»', ''),
                row.get('é¢è©¦æµç¨‹', ''),
                row.get('é¡§å•é¢è«‡å‚™è¨»', '')
            ))
            inserted += 1
            
            if (i + 1) % 20 == 0:
                print(f'  âœ“ å·²åŒ¯å…¥ {i + 1} å€‹...')
        
        except Exception as e:
            print(f'  âš ï¸  ç¬¬ {i + 1} å€‹éŒ¯èª¤ï¼š{e}')
            continue
    
    conn.commit()
    print(f'âœ… æˆåŠŸåŒ¯å…¥ {inserted} å€‹è·ç¼º')
    cursor.close()
    return inserted

def main():
    print('ğŸ”„ é–‹å§‹å¾ Google Sheets åŒ¯å…¥è³‡æ–™...\n')
    
    try:
        # é€£ç·šåˆ° PostgreSQL
        print(f'ğŸ”— é€£ç·šåˆ° PostgreSQL ({DB_CONFIG["host"]})...')
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # æª¢æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å»ºç«‹
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS candidates_pipeline (
                id VARCHAR(50) PRIMARY KEY,
                name VARCHAR(255),
                email VARCHAR(255),
                phone VARCHAR(20),
                location VARCHAR(100),
                current_position VARCHAR(255),
                years_experience INT,
                job_changes INT,
                avg_tenure_months INT,
                recent_gap_months INT,
                skills JSONB,
                education VARCHAR(255),
                source VARCHAR(100),
                work_history JSONB,
                leaving_reason TEXT,
                stability_score INT,
                education_details JSONB,
                personality JSONB,
                status VARCHAR(50),
                recruiter VARCHAR(100),
                notes TEXT,
                resume_url TEXT,
                created_at TIMESTAMP,
                updated_at TIMESTAMP,
                sync_to_sheets_at TIMESTAMP
            );
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS jobs_pipeline (
                id VARCHAR(50) PRIMARY KEY,
                position_name VARCHAR(255),
                client_company VARCHAR(255),
                department VARCHAR(100),
                open_positions INT,
                salary_range VARCHAR(100),
                key_skills JSONB,
                experience_required VARCHAR(100),
                education_required VARCHAR(100),
                location VARCHAR(100),
                job_status VARCHAR(50),
                language_required VARCHAR(100),
                special_conditions TEXT,
                industry_background VARCHAR(100),
                team_size VARCHAR(50),
                key_challenges TEXT,
                attractive_points TEXT,
                recruitment_difficulty TEXT,
                interview_process TEXT,
                consultant_notes TEXT,
                created_at TIMESTAMP,
                updated_at TIMESTAMP,
                sync_to_sheets_at TIMESTAMP
            );
        """)
        
        conn.commit()
        cursor.close()
        print('âœ… è³‡æ–™åº«é€£ç·šæˆåŠŸ\n')
        
        # ä¸‹è¼‰ä¸¦åŒ¯å…¥å€™é¸äººè³‡æ–™
        candidates_csv = fetch_csv(
            SHEETS['candidates']['sheet_id'],
            SHEETS['candidates']['gid'],
            SHEETS['candidates']['name']
        )
        
        if candidates_csv:
            rows = parse_csv(candidates_csv)
            import_candidates(conn, rows)
        
        # ä¸‹è¼‰ä¸¦åŒ¯å…¥è·ç¼ºè³‡æ–™
        jobs_csv = fetch_csv(
            SHEETS['jobs']['sheet_id'],
            SHEETS['jobs']['gid'],
            SHEETS['jobs']['name']
        )
        
        if jobs_csv:
            rows = parse_csv(jobs_csv)
            import_jobs(conn, rows)
        
        # é©—è­‰è³‡æ–™
        print('\n\nğŸ“ˆ åŒ¯å…¥çµæœçµ±è¨ˆï¼š')
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM candidates_pipeline')
        candidate_count = cursor.fetchone()[0]
        print(f'  å€™é¸äººï¼š{candidate_count} ä½')
        
        cursor.execute('SELECT COUNT(*) FROM jobs_pipeline')
        job_count = cursor.fetchone()[0]
        print(f'  è·ç¼ºï¼š{job_count} å€‹')
        
        cursor.close()
        conn.close()
        
        print('\nâœ… åŒ¯å…¥å®Œæˆï¼')
        
    except Exception as e:
        print(f'\nâŒ åŒ¯å…¥å¤±æ•—ï¼š{e}')
        sys.exit(1)

if __name__ == '__main__':
    main()
